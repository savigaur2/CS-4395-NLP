{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cDg3qVmEjdJe",
        "wPY-h7homGY9",
        "KmoNWCjqsFB0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# WordNet Protfolio Assignment"
      ],
      "metadata": {
        "id": "tPo7yXVcjMJE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "metadata": {
        "id": "9wLB8dMpkREW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6yZ8bmIkhFe",
        "outputId": "d83a3844-edb5-4400-d69e-8a953452a45b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Wordnet Summary:\n",
        "\n",
        "WordNet is a hierarchial organization of nouns, verbs, adjectives and adverbs listing glosses (short definitions), sysnets (synonym sets), use examples and relations to other words. It is a project started by the Priceton psychologist George Miller who wanted to investigate peoples' cocepts of hierarchial organization."
      ],
      "metadata": {
        "id": "cDg3qVmEjdJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Select a noun. Output all synsets"
      ],
      "metadata": {
        "id": "eL1QQhxQkJMa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJQQb5iki_uf",
        "outputId": "967ec30f-c0d3-4a4c-81e0-74fbdadffcef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('zanzibar_copal.n.01'), Synset('anime.n.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# get all synsets of 'anime'\n",
        "\n",
        "wn.synsets('anime')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Select one synset from the list of synsets. \n",
        "\n",
        "### 3.a Extract its definition, usage examples, and lemmas. "
      ],
      "metadata": {
        "id": "5ZCKcTqGk527"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Definition: ', wn.synset('anime.n.02').definition())\n",
        "print('Usage Examples: ', wn.synset('anime.n.02').examples())\n",
        "print('Lemmas: ', wn.synset('anime.n.02').lemmas())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWBxAGOXkcta",
        "outputId": "0137fc90-dd23-431b-bb82-81c45cb4465c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition:  any of various resins or oleoresins\n",
            "Usage Examples:  []\n",
            "Lemmas:  [Lemma('anime.n.02.anime'), Lemma('anime.n.02.gum_anime')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.b From your selected synset, traverse up the WordNet hierarchy as far as you can, outputting the synsets as you go"
      ],
      "metadata": {
        "id": "wiqbVTyHlo1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anime_synsets = wn.synsets('anime', pos = wn.NOUN)\n",
        "for sense in anime_synsets:\n",
        "    lemmas = [l.name() for l in sense.lemmas()]\n",
        "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap7IjkVHlI91",
        "outputId": "d20bd539-a521-453c-fb64-7a11be2c93ed"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: zanzibar_copal.n.01(a hard copal derived from an African tree)  \n",
            "\t Lemmas:['Zanzibar_copal', 'anime']\n",
            "Synset: anime.n.02(any of various resins or oleoresins)  \n",
            "\t Lemmas:['anime', 'gum_anime']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.c Write a couple of sentences observing the way that WordNet is organized for nouns.\n",
        "\n",
        "Nouns are the most highly-connected synets. Nouns are organized with a hierarchy, where the entity is at the top."
      ],
      "metadata": {
        "id": "wPY-h7homGY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Output the following (or an empty list if none exist): hypernyms, hyponyms, meronyms, holonyms, antonym. "
      ],
      "metadata": {
        "id": "PzNYWDetmRl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anime = wn.synset('anime.n.02')\n",
        "print('Hypernymns: ', anime.hypernyms())\n",
        "print('Hyponyms: ', anime.hyponyms())\n",
        "print('Meronyms: ', anime.part_meronyms())\n",
        "print('Holonyms: ', anime.part_holonyms())\n",
        "print('Antonym: ', anime.lemmas()[0].antonyms(), anime.lemmas()[1].antonyms())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqGYiTJwmEab",
        "outputId": "559c8252-2ae7-4688-fa5b-17c531de701b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hypernymns:  [Synset('natural_resin.n.01')]\n",
            "Hyponyms:  []\n",
            "Meronyms:  []\n",
            "Holonyms:  []\n",
            "Antonym:  [] []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Select a verb. Output all synsets."
      ],
      "metadata": {
        "id": "bCSF9Puzolrp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all synsets of 'sleep'\n",
        "\n",
        "wn.synsets('sleep')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXCvnUTNnCT5",
        "outputId": "68c846e2-d3bf-4197-d0b7-d941b4d290c4"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('sleep.n.01'),\n",
              " Synset('sleep.n.02'),\n",
              " Synset('sleep.n.03'),\n",
              " Synset('rest.n.05'),\n",
              " Synset('sleep.v.01'),\n",
              " Synset('sleep.v.02')]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Select one synset from the list of synsets.\n",
        "### 6.a Extract its definition, usage examples, and lemmas."
      ],
      "metadata": {
        "id": "7rhnYwb6rqEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Definition: ', wn.synset('rest.n.05').definition())\n",
        "print('Usage Examples: ', wn.synset('rest.n.05').examples())\n",
        "print('Lemmas: ', wn.synset('rest.n.05').lemmas())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Leg0YHjOrenr",
        "outputId": "e5e886b9-77d1-4406-f03f-51e4cf18ed24"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Definition:  euphemisms for death (based on an analogy between lying in a bed and in a tomb)\n",
            "Usage Examples:  ['she was laid to rest beside her husband', 'they had to put their family pet to sleep']\n",
            "Lemmas:  [Lemma('rest.n.05.rest'), Lemma('rest.n.05.eternal_rest'), Lemma('rest.n.05.sleep'), Lemma('rest.n.05.eternal_sleep'), Lemma('rest.n.05.quietus')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.b From your selected synset, traverse up the WordNet hierarchy as far as you can, outputting the synsets as you go"
      ],
      "metadata": {
        "id": "TbRMtYOAryyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sleep_synsets = wn.synsets('sleep', pos = wn.VERB)\n",
        "for sense in sleep_synsets:\n",
        "    lemmas = [l.name() for l in sense.lemmas()]\n",
        "    print(\"Synset: \" + sense.name() + \"(\" +sense.definition() + \")  \\n\\t Lemmas:\" + str(lemmas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM8wEO2vrmWE",
        "outputId": "f90b2529-eee3-4717-e8ea-da0cffa93dd5"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset: sleep.v.01(be asleep)  \n",
            "\t Lemmas:['sleep', 'kip', 'slumber', \"log_Z's\", \"catch_some_Z's\"]\n",
            "Synset: sleep.v.02(be able to accommodate for sleeping)  \n",
            "\t Lemmas:['sleep']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.c Write a couple of sentences observing the way that WordNet is organized for verbs.\n",
        "\n",
        "Verns can be in hypernym/hyponum relations. Unlike nouns, there is no top level for all verbs."
      ],
      "metadata": {
        "id": "KmoNWCjqsFB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Use morphy to find as many different forms of the word as you can. "
      ],
      "metadata": {
        "id": "wF2_-KKysJ13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('sleep', wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "waqYLRWFr4_s",
        "outputId": "11384857-14ba-42bd-fcd6-ee0273ad4905"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sleep'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('sleep', wn.NOUN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PqrYRSnWsfNo",
        "outputId": "c0e220e9-fead-4c2f-9998-963574437f77"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sleep'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('sleepy', wn.ADJ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "T5x4egzssXn6",
        "outputId": "2ebb9339-9a88-43f7-b4c6-bdfabc1bc709"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sleepy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('sleepier', wn.ADJ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HtCgqeB8sbP8",
        "outputId": "036d2563-576a-43b0-ce78-fe02961a9146"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sleepy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.morphy('slept', wn.VERB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u5LSdCH3sjie",
        "outputId": "2fa5f7e0-d34a-45be-a500-5975cd6d6e6b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sleep'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Select two words that you think might be similar.\n",
        "- make\n",
        "- create\n",
        "\n",
        "## 8.a Find the specific synsets you are interested in.\n",
        "\n",
        "- make.v.01\n",
        "- create.v.03"
      ],
      "metadata": {
        "id": "-qMJUNQGspJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Make synstets: ', wn.synsets('make'))\n",
        "print('Craete synstets: ', wn.synsets('create'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79jfZvaBsm0V",
        "outputId": "9889009d-6762-4fe7-918b-1c45635af640"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make synstets:  [Synset('brand.n.02'), Synset('shuffle.n.01'), Synset('make.v.01'), Synset('make.v.02'), Synset('make.v.03'), Synset('induce.v.02'), Synset('cause.v.01'), Synset('produce.v.02'), Synset('draw.v.04'), Synset('make.v.08'), Synset('create.v.05'), Synset('gain.v.08'), Synset('do.v.08'), Synset('form.v.02'), Synset('reach.v.07'), Synset('make.v.14'), Synset('make.v.15'), Synset('make.v.16'), Synset('construct.v.01'), Synset('make.v.18'), Synset('make.v.19'), Synset('name.v.03'), Synset('have.v.17'), Synset('reach.v.01'), Synset('lay_down.v.01'), Synset('make.v.24'), Synset('make.v.25'), Synset('hold.v.03'), Synset('make.v.27'), Synset('take.v.27'), Synset('stool.v.04'), Synset('make.v.30'), Synset('make.v.31'), Synset('make.v.32'), Synset('make.v.33'), Synset('make.v.34'), Synset('make.v.35'), Synset('make.v.36'), Synset('make.v.37'), Synset('make.v.38'), Synset('cook.v.02'), Synset('seduce.v.01'), Synset('make.v.41'), Synset('make.v.42'), Synset('make.v.43'), Synset('make.v.44'), Synset('make.v.45'), Synset('make.v.46'), Synset('make.v.47'), Synset('make.v.48'), Synset('make.v.49')]\n",
            "Craete synstets:  [Synset('make.v.03'), Synset('create.v.02'), Synset('create.v.03'), Synset('create.v.04'), Synset('create.v.05'), Synset('produce.v.02')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8.a Run the Wu-Palmer similarity metric and the Lesk algorithm. Write a couple of sentences with your observations.\n",
        "\n",
        "From the code below, we can see that the chosen synsets from above have a Wu palmer similarity score of 0.4. This means that they are not too similar. Additionally, looking at the lesk algorthim ran on 'make' and 'crate; using the context senteces below, we see that the synsets most relevant to ake and create are make.v.02 and create.v.04 respectively"
      ],
      "metadata": {
        "id": "9u9s9XuqPI1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "make = wn.synset('make.v.01')\n",
        "create = wn.synset('create.v.03')"
      ],
      "metadata": {
        "id": "RxX1UKSOOwP5"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wn.wup_similarity(make, create)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLECc0icPX1z",
        "outputId": "4abbebbb-0906-4906-b5ad-94560545eee3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk"
      ],
      "metadata": {
        "id": "akEjTuV4PhyA"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_sent = 'I like to make sandwiches when I am hungry'.split(' ')\n",
        "create_sent = 'I like to create new characters in NBA2k when I get bored with the default rosters'.split(' ')\n",
        "\n",
        "print(lesk(make_sent, 'make', pos = 'v'))\n",
        "print(lesk(create_sent, 'create', pos = 'v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQC-N3IFPbiF",
        "outputId": "14a8b76d-94e5-4c9c-d42f-15680dd4cb02"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('make.v.42')\n",
            "Synset('create.v.04')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Write a couple of sentences about SentiWordNet, describing its functionality and possible use cases. \n",
        "\n",
        "SentiWordNet is built on top of WordNet and assigns 3 scores: positive, negative, objectivity. SentiWordNet requires that a corpus already be downloaded and performe sentiment analysis to see if text is postive/neative ot objective/subjective. Use cases include seeing which product reviews are postive/negative in order to find which aspects of a product customers are happy/unhappy about for further improvements/innovations"
      ],
      "metadata": {
        "id": "IEQ0tYbGSx5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.a Select an emotionally charged word. Find its senti-synsets and output the polarity scores for each word."
      ],
      "metadata": {
        "id": "qmsKgPxNTqft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import sentiwordnet as swn\n",
        "nltk.download('sentiwordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL2VkBrIQP46",
        "outputId": "c3b69c7e-a0e7-41d8-ed5b-45d4a41d9d78"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package sentiwordnet to /root/nltk_data...\n",
            "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synsets('sad')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px1SKqcLT4b5",
        "outputId": "d23780f1-8fb1-4116-e040-e109c2751d46"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('sad.a.01'), Synset('sad.s.02'), Synset('deplorable.s.01')]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wn.synset('sad.a.01').definition()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UXbTJINpVTXL",
        "outputId": "224adb3b-77ae-4357-9b33-e4e8cf71e508"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'experiencing or showing sorrow or unhappiness; ; - Christina Rossetti'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sad = swn.senti_synset('sad.a.01')\n",
        "print(\"Positive score = \", sad.pos_score())\n",
        "print(\"Negative score = \", sad.neg_score())\n",
        "print(\"Objective score = \", sad.obj_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XtDf5NoVWkM",
        "outputId": "29aaa7e7-5692-4952-9a83-76fcb613c9e9"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive score =  0.125\n",
            "Negative score =  0.75\n",
            "Objective score =  0.125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.b Make up a sentence. Output the polarity for each word in the sentence."
      ],
      "metadata": {
        "id": "591MlM-mVz0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent = 'i am very excited to see the new anime releasing during the upcoming fall season'.split(' ')"
      ],
      "metadata": {
        "id": "CwQaTtrUVl2l"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sent:\n",
        "    if len(wn.synsets(word)) > 0:\n",
        "        syn = wn.synsets(word)[0].name()\n",
        "        print(syn)\n",
        "        senti_syn = swn.senti_synset(syn)\n",
        "        print(senti_syn)\n",
        "        print(\"Positive score = \", senti_syn.pos_score())\n",
        "        print(\"Negative score = \", senti_syn.neg_score())\n",
        "        print(\"Objective score = \", senti_syn.obj_score())\n",
        "        print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLWqkOoUWELk",
        "outputId": "7171e2a7-d67a-4f8c-d057-453330b09d66"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iodine.n.01\n",
            "<iodine.n.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "americium.n.01\n",
            "<americium.n.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "very.s.01\n",
            "<very.s.01: PosScore=0.5 NegScore=0.0>\n",
            "Positive score =  0.5\n",
            "Negative score =  0.0\n",
            "Objective score =  0.5\n",
            "\n",
            "excite.v.01\n",
            "<excite.v.01: PosScore=0.25 NegScore=0.375>\n",
            "Positive score =  0.25\n",
            "Negative score =  0.375\n",
            "Objective score =  0.375\n",
            "\n",
            "see.n.01\n",
            "<see.n.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "new.a.01\n",
            "<new.a.01: PosScore=0.375 NegScore=0.0>\n",
            "Positive score =  0.375\n",
            "Negative score =  0.0\n",
            "Objective score =  0.625\n",
            "\n",
            "zanzibar_copal.n.01\n",
            "<zanzibar_copal.n.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "let_go_of.v.01\n",
            "<let_go_of.v.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "approaching.s.01\n",
            "<approaching.s.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "fall.n.01\n",
            "<fall.n.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n",
            "season.n.01\n",
            "<season.n.01: PosScore=0.0 NegScore=0.0>\n",
            "Positive score =  0.0\n",
            "Negative score =  0.0\n",
            "Objective score =  1.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9.c Write a couple of sentences about your observations of the scores and the utility of knowing these scores in an NLP application. \n",
        "\n",
        "Looking at the polarity scores for my sentence, I notice that most of the words are objective. This makes sence as most of the words were nouns that do not carry too much meaning. Surprisingly, the word 'excite' only had a positivity score of 0.25, with a higher negativity score of 0.35. This is surpsing because, given the context of the sentence, I ould expect the positivity score to be much higher than the negativity score. This is likely due to the way I selected the synsets to pass into the senti_synsets function. Selecting the first synset of a word might not always garuntee that the correct meaning of the word is bein conveyed. For example, words like 'i' and 'anime' have bizzare first synsets. Because of this, I think using the lesk algorithm to first find the appropriate synsets and then feeding those into the senti_synets function would be better. In an NLP application that first finds the correct synsets, the polarity scores could be very insightfull in the feild of product analytics or any space with customer reviews. These polarity scores could very easily help an organization gage how their target population is responding to products or new changes."
      ],
      "metadata": {
        "id": "zrdON435YlfU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Write a couple of sentences about what a collocation is. \n",
        "\n",
        "A collocation is when two or more words combine more often than expected by chance, and you cannot sunstitute a word and get the same meaning. These can be found with point-wise mutual information (PMI):\n",
        "\n",
        "$ PMI = log_2\\frac{P(x, y)}{P(x)P(y)}$\n",
        "\n",
        "- PMI = 0: x and y are independent\n",
        "- PMI > 0: likely to be a collocation\n",
        "- PMI < 0: not likely to be a collocation"
      ],
      "metadata": {
        "id": "2aMXX4J7acTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.b Output collocations for text4, the Inaugural corpus"
      ],
      "metadata": {
        "id": "1E52nmV-eAEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('inaugural')\n",
        "nltk.download('nps_chat')\n",
        "nltk.download('webtext')\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.book import text4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e5xovRkX-ui",
        "outputId": "3d634d06-1e41-488c-a2eb-e415d1cfe0dc"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n",
            "[nltk_data] Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]   Package nps_chat is already up-to-date!\n",
            "[nltk_data] Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]   Package webtext is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text4.collocations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxtayOCVeMje",
        "outputId": "808e950c-e5c6-4d8d-cdbf-407f1def90f4"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "United States; fellow citizens; years ago; four years; Federal\n",
            "Government; General Government; American people; Vice President; God\n",
            "bless; Chief Justice; one another; fellow Americans; Old World;\n",
            "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
            "tribes; public debt; foreign nations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10.c Select one of the collocations identified by NLTK. Calculate mutual information. Write commentary on the results of the mutual information formula and your interpretation. \n",
        "\n",
        "Looking at the code below, we see that PMI for United States is around 4.815. Looking specifically at $P(United States)$, $P(United)$ and $P(States)$, we see that the values are around 0.016, 0.017 and 0.033 respectively. This means that the word 'States' occurs more often than 'United'. Also since $P(States) > P(United States) $ , 'States' appears more times than the combination of 'United' and 'States'. However, since the $PMI$ is larger than 0, we can say that it is likely that 'United States' is a collocation."
      ],
      "metadata": {
        "id": "isFHrkNTe41h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "kklODxXoeyvg"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(text4.tokens)\n",
        "text[:50] "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I9YONSwwkHIB",
        "outputId": "c612b334-1c0b-44e8-e5d7-69c39597e58b"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Fellow - Citizens of the Senate and of the House o'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = len(set(text4))\n",
        "\n",
        "p_US = text.count('United States') / vocab\n",
        "print('p(United States) = ', p_US)\n",
        "\n",
        "p_United = text.count('United') / vocab\n",
        "print('p(United) = ', p_United)\n",
        "\n",
        "p_States = text.count('States') / vocab\n",
        "print('p(States) = ', p_States)\n",
        "\n",
        "pmi = math.log2(p_US / (p_United * p_States))\n",
        "print('PMI = ', pmi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDdfUrG2kPm-",
        "outputId": "8c325fb5-aa28-41f6-a9f6-ed561b0718f0"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(United States) =  0.015860349127182045\n",
            "p(United) =  0.0170573566084788\n",
            "p(States) =  0.03301745635910224\n",
            "PMI =  4.815657649820885\n"
          ]
        }
      ]
    }
  ]
}